---
title: "Eagle 2.5: Boosting Long-Context Post-Training for Frontier Vision-Language Models"
collection: publications
permalink: /publication/2025-eagle2.5
date: 2025-12-01
year: '2025'
venue: 'NeruIPS'
citation: 'Guo Chen, Zhiqi Li, Shihao Wang, Jindong Jiang, Yicheng Liu, Lidong Lu, De-An Huang, <b> Wonmin Byeon </b>, Matthieu Le, Tuomas Rintamaki, Tyler Poon, Max Ehrlich, Tuomas Rintamaki, Tyler Poon, Tong Lu, Limin Wang, Bryan Catanzaro, Jan Kautz, Andrew Tao, Zhiding Yu, Guilin Liu</b> <b>|</b> <i> NeruIPS 2025 </i> '
paperurl: 'https://arxiv.org/pdf/2504.15271'
---
[[arxiv]](https://arxiv.org/abs/2504.15271)&nbsp;


## Abstract
We introduce Eagle 2.5, a family of frontier vision-language models (VLMs) for long-context multimodal learning. Our work addresses the challenges in long video comprehension and high-resolution image understanding, introducing a generalist framework for both tasks. The proposed training framework incorporates Automatic Degrade Sampling and Image Area Preservation, two techniques that preserve contextual integrity and visual details. The framework also includes numerous efficiency optimizations in the pipeline for long-context data training. Finally, we propose Eagle-Video-110K, a novel dataset that integrates both story-level and clip-level annotations, facilitating long-video understanding. Eagle 2.5 demonstrates substantial improvements on long-context multimodal benchmarks, providing a robust solution to the limitations of existing VLMs. Notably, our best model Eagle 2.5-8B achieves 72.4% on Video-MME with 512 input frames, matching the results of top-tier commercial model such as GPT-4o and large-scale open-source models like Qwen2.5-VL-72B and InternVL2.5-78B.

```bib
@misc{chen2025eagle25boostinglongcontext,
      title={Eagle 2.5: Boosting Long-Context Post-Training for Frontier Vision-Language Models}, 
      author={Guo Chen and Zhiqi Li and Shihao Wang and Jindong Jiang and Yicheng Liu and Lidong Lu and De-An Huang and Wonmin Byeon and Matthieu Le and Tuomas Rintamaki and Tyler Poon and Max Ehrlich and Tuomas Rintamaki and Tyler Poon and Tong Lu and Limin Wang and Bryan Catanzaro and Jan Kautz and Andrew Tao and Zhiding Yu and Guilin Liu},
      year={2025},
      eprint={2504.15271},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2504.15271}, 
}
```

