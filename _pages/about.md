---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

News
======

* Our [token-efficient long video model for multimodal LLMs](https://wonmin-byeon.github.io/publication/2025-storm) (STORM) is on arXiv. It achieves more than 5\% improvement on MLVU and LongVideoBench compared to SOTA while reducing the computation costs by up to 8× and the decoding latency by 2.4-2.9×. Check the [project page](https://research.nvidia.com/labs/lpr/storm/) for the details!

* We intoduce efficient [2D parallel sequence modeling](https://wonmin-byeon.github.io/publication/2025-gspn) for image classifcaiton and generation. The paper is accepted to CVPR 2025!

* Another [Mamba-Transformer Hybrid LLM](https://wonmin-byeon.github.io/publication/2025-hymba) is on arxiv! Check the [blog post](https://developer.nvidia.com/blog/hymba-hybrid-head-architecture-boosts-small-language-model-performance/). The paper is accepted as a Spotlight to ICLR 2025!

* We've released a new [8B Mamba-based Hybrid LLM](https://wonmin-byeon.github.io/publication/2024-hybrid)! The checkpoints as well as the code are also released as part of [NVIDIA's Megatron-LM project](https://github.com/NVIDIA/megatron-LM/tree/ssm/examples/mamba). I gave a [talk](https://www.youtube.com/watch?v=wgcsfLP4Cbw&t=1s) at KAIST.

* [1 paper](https://wonmin-byeon.github.io/publication/2024-mtvg) accepted to ECCV 2024.

* [1 paper](https://wonmin-byeon.github.io/publication/2024-regiongpt) accepted to CVPR 2024.

* [1 paper](https://wonmin-byeon.github.io/publication/2023-convssm) accepted to NeurIPS 2023.

<!-- * [1 paper](https://wonmin-byeon.github.io/publication/2023-PowerofSound) accepted to ICCV 2023. [2 papers](https://wonmin-byeon.github.io/publications/) accepted to CVPR 2023. -->

<!-- * Our paper ["Physics Informed RNN-DCT Networks for Time-Dependent Partial Differential Equations"](https://wonmin-byeon.github.io/publication/2022-rnndct) is now in [NVIDIA Modulus](https://developer.nvidia.com/modulus)! Check out [technical blog](https://developer.nvidia.com/blog/develop-physics-informed-machine-learning-models-with-graph-neural-networks/) and [Modulus repo](https://github.com/NVIDIA/modulus/tree/main/modulus/models/rnn). -->

Research Interests
======
* Recurrent Neural Network (RNN), State-Space Models (SSM), Linear RNNs

* Sequence Learning, Spatio-Temporal Learning

Selected Projects
======
* J Jiang*, X Li*, Z Liu, M Li, G Chen, Z Li, D Huang, G Liu, Z Yu, K Keutzer, S Ahn, J Kautz, H Yin, Y Lu, S Han, <b>W Byeon</b>, ["Token-Efficient Long Video Understanding for Multimodal LLMs"](https://wonmin-byeon.github.io/publication/2025-storm), arXiv, 2025

* H Wang, <b>W Byeon</b>, J Xu, J Gu, KC Cheung, X Wang, K Han, J Kautz, S Liu, ["Parallel Sequence Modeling via Generalized Spatial Propagation Network"](https://wonmin-byeon.github.io/publication/2025-gspn), CVPR, 2025

* X Dong, Y Fu, S Diao, <b>W Byeon</b>, Z Chen, A S Mahabaleshwarkar, S Liu, M Keirsbilck, M Chen, Y Suhara, Y Lin, J Kautz, P Molchanov, ["Hymba: A Hybrid-head Architecture for Small Language Models"](https://wonmin-byeon.github.io/publication/2025-hymba), ICLR, 2025

* R Waleffe, <b>W Byeon</b>, D Riach, B Norick, V Korthikanti, T Dao, A Gu, A Hatamizadeh, S Singh, D Narayanan, G Kulshreshtha, V Singh, J Casper, J Kautz, M Shoeybi, B Catanzaro, ["An Empirical Study of Mamba-based Language Models"](https://wonmin-byeon.github.io/publication/2024-hybrid), arXiv, 2024

* J T.H. Smith, S De Mello, J Kautz, S W. Linderman, <b>W Byeon</b>, ["Convolutional State Space Models for Long-Range Spatiotemporal Modeling"](https://wonmin-byeon.github.io/publication/2023-convssm), NeurIPS, 2023

<!-- * J Su, <b>W Byeon</b>, F Huang, ["Scaling-up Diverse Orthogonal Convolutional Networks with a Paraunitary Framework"](https://wonmin-byeon.github.io/publication/2022-orthoNN), ICML, 2022 -->

<!-- * B Wu*, O Hennigh, J Kautz, S Choudhry, <b>W Byeon*</b>, ["Physics Informed RNN-DCT Networks for Time-Dependent Partial Differential Equations"](https://wonmin-byeon.github.io/publication/2022-rnndct), ICCS 2022 <b> (*) equal contributions </b>
    - Presented at NeurIPS'21 Workshop on ML and the Physical Science
    - Released as part of [NVIDIA Mudulus](https://developer.nvidia.com/modulus)  -->

<!-- * J Su*, <b>W Byeon*</b>, F Huang, J Kautz, A Anandkumar, ["Convolutional Tensor-Train LSTM for Spatio-temporal Learning"](https://wonmin-byeon.github.io/publication/2020-convttlstm), NeurIPS 2020 <b> (*) equal contributions </b> 
    - Presented at ECCV'20 Tutorial on Accelerating Computer Vision with Mixed Precision. 
 -->    
<!-- * <b>W Byeon</b>, Q Wang, R K Srivastava, P Koumoutsakos, ["ContextVP: Fully Context-Aware Video Prediction"](https://wonmin-byeon.github.io/publication/2018-contextvp), ECCV 2018 (oral) -->

<!-- * PR Vlachas, <b>W Byeon</b>, ZY Wan, TP Sapsis, P Koumoutsakos, ["Data-Driven Forecasting of High-Dimensional Chaotic Systems with Long Short-Term Memory Networks"](https://wonmin-byeon.github.io/publication/2018-05-01-chaotic-lstm), Proceedings of the Royal Society A: Mathematical, Physical & Engineering Sciences. 2018 -->
